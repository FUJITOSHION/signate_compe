{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FUJITOSHION/signate_compe/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfvxzzFBRj0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dec614d8-aab2-47b1-ef4f-d908bdd36e25"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoUyjQ1RRrr2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "d8d57802-5ffe-403f-fb32-806cfa52ada9"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izuRkSW9Rf9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "# from transformers.modeling_bert import BertModel\n",
        "from transformers import BertTokenizer, BertForPreTraining, BertModel,BertForSequenceClassification\n",
        "from sklearn.metrics import precision_score\n",
        "import torch\n",
        "from torch import nn\n",
        "import json\n",
        "import torchtext\n",
        "import string\n",
        "import random\n",
        "import sys\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import lightgbm as lgb\n",
        "from matplotlib_venn import venn2\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT6p55ojRf9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/My Drive/data/train1.csv')\n",
        "df_test = pd.read_csv('/content/drive/My Drive/data/test1.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VliacrO0Rf9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6ed698ce-bacf-4393-9779-bc9ee3008581"
      },
      "source": [
        "df_train['jobflag'] = df_train['jobflag'] -1\n",
        "df_train['jobflag'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1376\n",
              "0     624\n",
              "3     583\n",
              "1     348\n",
              "Name: jobflag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhYjVnTbx7fx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "19428ed6-be75-4984-d0e0-635d1cb1e554"
      },
      "source": [
        "import numpy as np\n",
        "del df_train['id']\n",
        "df_train.drop_duplicates(subset='description', keep='last', inplace=True)\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_train['id'] = np.arange(2905)\n",
        "df_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>jobflag</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Executes and writes portions of testing plans,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Maintain Network Performance by assisting with...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Supports the regional compliance manager with ...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Keep up to date with local and national busine...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Assist with Service Organization Control (SOC)...</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2900</th>\n",
              "      <td>Preparation of reports for operational and man...</td>\n",
              "      <td>2</td>\n",
              "      <td>2900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2901</th>\n",
              "      <td>Line and/or indirect management of up to 20 st...</td>\n",
              "      <td>2</td>\n",
              "      <td>2901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2902</th>\n",
              "      <td>Partner with external agencies as needed</td>\n",
              "      <td>0</td>\n",
              "      <td>2902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2903</th>\n",
              "      <td>Design, Implement and test software for embedd...</td>\n",
              "      <td>2</td>\n",
              "      <td>2903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2904</th>\n",
              "      <td>Undertake to preprocess of structured and unst...</td>\n",
              "      <td>1</td>\n",
              "      <td>2904</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2905 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            description  jobflag    id\n",
              "0     Executes and writes portions of testing plans,...        1     0\n",
              "1     Maintain Network Performance by assisting with...        2     1\n",
              "2     Supports the regional compliance manager with ...        3     2\n",
              "3     Keep up to date with local and national busine...        0     3\n",
              "4     Assist with Service Organization Control (SOC)...        3     4\n",
              "...                                                 ...      ...   ...\n",
              "2900  Preparation of reports for operational and man...        2  2900\n",
              "2901  Line and/or indirect management of up to 20 st...        2  2901\n",
              "2902           Partner with external agencies as needed        0  2902\n",
              "2903  Design, Implement and test software for embedd...        2  2903\n",
              "2904  Undertake to preprocess of structured and unst...        1  2904\n",
              "\n",
              "[2905 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnGIp2SaRf94",
        "colab_type": "text"
      },
      "source": [
        "## tokenizer and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fteim849Rf94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_bert = BertTokenizer(vocab_file='/content/drive/My Drive/vocab/bert-base-uncased-vocab.txt')\n",
        "\n",
        "def preprocessing(text):\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "\n",
        "def token_same_len(token):\n",
        "    token.insert(0,'[CLS]')\n",
        "    if len(token) < 512:\n",
        "        while len(token) != 512:\n",
        "            token.insert(512,'[PAD]')\n",
        "    token.insert(128,['SEP'])\n",
        "    return token\n",
        "\n",
        "def token_and_prepro(text, tokenizer = tokenizer_bert):\n",
        "    text = preprocessing(text)\n",
        "    token = tokenizer.tokenize(text)\n",
        "    token = token_same_len(token)\n",
        "    ids = tokenizer.convert_tokens_to_ids(token[:128])\n",
        "    return ids"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXfn6j5IRf96",
        "colab_type": "text"
      },
      "source": [
        "## dataset(torchtext)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VvTLJpORf97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer,token_same_len):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.token_same_len = token_same_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, input_ids):\n",
        "        text = self.df['description'][input_ids]\n",
        "        label = self.df['jobflag'][input_ids]\n",
        "        id = self.df['id'][input_ids]\n",
        "        \n",
        "        token = self.tokenizer(text)\n",
        "        \n",
        "        tensor_token = torch.tensor(token)\n",
        "        tensor_label = torch.tensor(label)\n",
        "        \n",
        "        return tensor_token, tensor_label, id"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aslS1UYLRf99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer,token_same_len):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.token_same_len = token_same_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, input_ids):\n",
        "        text = self.df['description'][input_ids]\n",
        "        id = self.df['id'][input_ids]\n",
        "        \n",
        "        token = self.tokenizer(text)\n",
        "        \n",
        "        tensor_token = torch.tensor(token)\n",
        "        \n",
        "        return tensor_token, id"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Lcg9kmBRf9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# del df_test['id']\n",
        "dataset = Dataset(df = df_train, tokenizer = token_and_prepro,token_same_len=token_same_len)\n",
        "test_dataset = TestDataset(df = df_test, tokenizer = token_and_prepro,token_same_len=token_same_len)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), int(len(dataset)*0.2)])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0XhpUerFxwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.sampler import BatchSampler\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "    \"\"\"\n",
        "    BatchSampler - from a MNIST-like dataset, samples n_classes and within these classes samples n_samples.\n",
        "    Returns batches of size n_classes * n_samples\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, n_classes, n_samples):\n",
        "        loader = DataLoader(dataset)\n",
        "        self.labels_list = []\n",
        "        for _, label,id in loader:\n",
        "            self.labels_list.append(label)\n",
        "        self.labels = torch.LongTensor(self.labels_list)\n",
        "        self.labels_set = list(set(self.labels.numpy()))\n",
        "        self.label_to_indices = {label: np.where(self.labels.numpy() == label)[0]\n",
        "                                 for label in self.labels_set}\n",
        "        for l in self.labels_set:\n",
        "            np.random.shuffle(self.label_to_indices[l])\n",
        "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
        "        self.count = 0\n",
        "        self.n_classes = n_classes\n",
        "        self.n_samples = n_samples\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = self.n_samples * self.n_classes\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.count = 0\n",
        "        while self.count + self.batch_size < len(self.dataset):\n",
        "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
        "            indices = []\n",
        "            for class_ in classes:\n",
        "                indices.extend(self.label_to_indices[class_][\n",
        "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
        "                                                                         class_] + self.n_samples])\n",
        "                self.used_label_indices_count[class_] += self.n_samples\n",
        "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
        "                    np.random.shuffle(self.label_to_indices[class_])\n",
        "                    self.used_label_indices_count[class_] = 0\n",
        "            yield indices\n",
        "            self.count += self.n_classes * self.n_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset) // self.batch_size"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in7OCMIXF38y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sampler = BalancedBatchSampler(train_dataset, 4, 4)\n",
        "#train\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_sampler)\n",
        "#val\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size= 16, shuffle=False)\n",
        "#test\n",
        "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = False)\n",
        "#loader_dict\n",
        "load_dict = {\"train\":train_dataloader, 'val':val_dataloader,'test':dl_test}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aNRdRq3Rf-B",
        "colab_type": "text"
      },
      "source": [
        "## dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZq7Ke1Ui-Lw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a068ed6a-ce2a-4a07-fad9-7d1dd91ec254"
      },
      "source": [
        "print(tokenizer_bert.convert_ids_to_tokens(val_dataset.__getitem__(1)[0]))\n",
        "print(val_dataset.__getitem__(1)[2])\n",
        "print(df_train['description'][1757])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'expertise', 'with', 'c', ',', 'python', ',', 'and', 'real', '-', 'time', 'control', 'interfaces', 'in', 'a', 'windows', 'environment', ';', 'accomplished', 'with', 'data', 'management', 'and', 'analysis', 'tools', '.', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "899\n",
            "Review results with customer (within 2 days of job completion  if possible).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTDMTnvdRf-F",
        "colab_type": "text"
      },
      "source": [
        "## model構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQcNhaGARf-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertModel.from_pretrained(pretrained_model_name_or_path='bert-base-uncased')\n",
        "# model1 =BertForSequenceClassification.from_pretrained(pretrained_model_name_or_path='bert-base-uncased',num_labels=4)\n",
        "# print(model1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDi37mJmRf-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.bert = model\n",
        "        # self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(in_features=768, out_features=4)\n",
        "#         self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        nn.init.normal_(self.classifier.weight, std=0.02)\n",
        "        nn.init.normal_(self.classifier.bias, 0)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        output = self.bert(inputs)\n",
        "        vec_0 = output[0]  \n",
        "        vec_0 = vec_0[:, 0, :] \n",
        "        vec_0 = vec_0.view(-1, 768)\n",
        "        \n",
        "        result = self.classifier(vec_0)\n",
        "        \n",
        "        return result"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCBwODPvRf-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9860e917-b294-4bdd-fad6-e00be2814c39"
      },
      "source": [
        "bert_model = BERT()\n",
        "bert_model.train()\n",
        "print('a')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-nNWVJSRf-M",
        "colab_type": "text"
      },
      "source": [
        "### 勾配の計算場所"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD2YRe5URf-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.勾配計算Falseにする（ALl）\n",
        "for param in bert_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. BertLayer[12]そう目\n",
        "for param in bert_model.bert.encoder.layer[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 3. label\n",
        "for param in bert_model.classifier.parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0JWPWF3Rf-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b54e3c47-21a0-4fc8-fcae-17ac69e67838"
      },
      "source": [
        "df_train['jobflag'].value_counts()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1364\n",
              "0     622\n",
              "3     579\n",
              "1     340\n",
              "Name: jobflag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mctMcCX8Rf-Q",
        "colab_type": "text"
      },
      "source": [
        "### oprimzer and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLSsNOuDqdT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def metric_f1(preds, data):\n",
        "    \"\"\"F1 evaluation function for lgbm model.\n",
        "    \"\"\"\n",
        "    y_true = data.get_label()\n",
        "    preds = preds.reshape(4, len(preds) // 4)\n",
        "    y_pred = np.argmax(preds, axis=0)\n",
        "    score = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    return \"metric_f1\", score, True"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwxcECJIRf-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    net.to(device)\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    # batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "    batch_size = 16\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()\n",
        "            else:\n",
        "                net.eval()\n",
        "\n",
        "            epoch_loss = 0.0\n",
        "            f1_batch =0\n",
        "            epoch_corrects = 0\n",
        "            iteration = 1\n",
        "            c = 0\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書型変数\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = batch[0].to(device)  # 文章\n",
        "                labels = batch[1].to(device)  # ラベル\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # BERTに入力\n",
        "                    outputs = net(inputs)\n",
        "                    \n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if (iteration % 25 == 0):  # 10iterに1度、lossを表示\n",
        "                            acc = (torch.sum(preds == labels.data)\n",
        "                                   ).double()/batch_size\n",
        "                            f1 = precision_score(preds.cpu().numpy(),\n",
        "                                                 labels.data.cpu().numpy(),\n",
        "                                                 average='macro')\n",
        "                            print(' All / batch　{} || Loss: {:.4f} | ACC：{}　| F1 :{}'.format(\n",
        "                                iteration, loss.item(),  acc, f1))\n",
        "                    \n",
        "                    \n",
        "\n",
        "                    iteration += 1\n",
        "\n",
        "                    # 損失と正解数の合計を更新\n",
        "                    epoch_loss += loss.item() * batch_size\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "                    f1_batch += f1_score(preds.to('cpu').detach().clone().numpy(), \n",
        "                                   labels.data.to('cpu').detach().clone().numpy(), \n",
        "                                   average='macro')\n",
        "                    # print(f1_batch)\n",
        "                    # if c ==26:\n",
        "                    #     sys.exit()\n",
        "                    # c +=1\n",
        "                    # print(c)\n",
        "                    # f1_batch += precision_score(preds.cpu().numpy(),\n",
        "                    #                         labels.data.cpu().numpy(),\n",
        "                    #                         average='macro')\n",
        "                    # print(f1_batch)\n",
        "                        \n",
        "            # epochごとのlossと正解率\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "            # f1s = f1_batch/ len(dataloaders_dict[phase].dataset)\n",
        "            # epoch_f1 = f1_batch/len(dataloaders_dict[phase].dataset)\n",
        "            ##########lineに送信##########################\n",
        "            if phase != 'train':\n",
        "                url = \"https://notify-api.line.me/api/notify\"\n",
        "                token = 'tQSMjodBp3mHEA6wGscIofzVyDUquKliy6diNv5eP78'\n",
        "                headers = {\"Authorization\" : \"Bearer \"+ token}\n",
        "                message =  'Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                            phase, epoch_loss, epoch_acc)\n",
        "                payload = {\"message\" :  message}\n",
        "                r = requests.post(url ,headers = headers ,params=payload)\n",
        "            ###############################################\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}  F1{}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc,1))\n",
        "\n",
        "    return net"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvh0wErkRf-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# BERTの元の部分はファインチューニング\n",
        "optimizer = optim.Adam([\n",
        "    {'params': bert_model.bert.encoder.layer[-1].parameters(), 'lr': 4e-5},\n",
        "    {'params': bert_model.classifier.parameters(), 'lr': 8e-5}\n",
        "])\n",
        "\n",
        "# 損失関数の設定\n",
        "# weights = torch.tensor([2.2,4.0,1.0,2.35]).cuda()\n",
        "# criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riLG9iCxRf-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "67399509-19a0-433d-de9a-956e16131e07"
      },
      "source": [
        "import requests\n",
        "num_epochs = 2\n",
        "net_trained = train_model(bert_model, load_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)\n",
        "#save\n",
        "# torch.save(net_trained.state_dict(), 'model.pth')\n",
        "#load\n",
        "# the_model = TheModelClass(*args, **kwargs)\n",
        "# the_model.load_state_dict(torch.load('model.pth'))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " All / batch　25 || Loss: 0.9336 | ACC：0.5625　| F1 :0.5625\n",
            " All / batch　50 || Loss: 0.8957 | ACC：0.6875　| F1 :0.6875\n",
            " All / batch　75 || Loss: 0.9350 | ACC：0.6875　| F1 :0.6875\n",
            " All / batch　100 || Loss: 0.8994 | ACC：0.625　| F1 :0.625\n",
            " All / batch　125 || Loss: 0.8596 | ACC：0.6875　| F1 :0.6875\n",
            "Epoch 1/2 | train |  Loss: 0.9467 Acc: 0.5942  F11\n",
            "Epoch 1/2 |  val  |  Loss: 1.0483 Acc: 0.5869  F11\n",
            " All / batch　25 || Loss: 1.1393 | ACC：0.4375　| F1 :0.4375\n",
            " All / batch　50 || Loss: 0.6967 | ACC：0.6875　| F1 :0.6875\n",
            " All / batch　75 || Loss: 0.8000 | ACC：0.625　| F1 :0.625\n",
            " All / batch　100 || Loss: 0.7718 | ACC：0.625　| F1 :0.625\n",
            " All / batch　125 || Loss: 0.6553 | ACC：0.75　| F1 :0.75\n",
            "Epoch 2/2 | train |  Loss: 0.8952 Acc: 0.6244  F11\n",
            "Epoch 2/2 |  val  |  Loss: 1.1572 Acc: 0.5456  F11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmEoRb6Wvzx9",
        "colab_type": "text"
      },
      "source": [
        "## 誤差分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFpe5OXtv2x6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "def make_df(phase):\n",
        "    preds_list = []\n",
        "    label_list = []\n",
        "    outputs1_list = []\n",
        "    outputs2_list = []\n",
        "    outputs3_list = []\n",
        "    outputs4_list = []\n",
        "    id_list = []\n",
        "    df_error = pd.DataFrame()\n",
        "    df_errors = pd.DataFrame()\n",
        "\n",
        "\n",
        "    if phase == 'test':\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        bert_model.eval()\n",
        "        bert_model.to(device)\n",
        "        for batch in tqdm(load_dict[phase]): \n",
        "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "            inputs = batch[0].to(device)\n",
        "            id_list.extend(batch[1].to('cpu').detach().clone().numpy())\n",
        "            \n",
        "            with torch.set_grad_enabled(False):\n",
        "                outputs_ = net_trained(inputs)\n",
        "                # loslogits = outputs\n",
        "                _, preds = torch.max(outputs_, 1)  # ラベルを予測\n",
        "                preds_list.extend(preds.to('cpu').detach().clone().numpy())\n",
        "                outputs = torch.t(outputs_).to('cpu').detach().clone().numpy()\n",
        "                outputs1_list.extend(outputs[0])\n",
        "                outputs2_list.extend(outputs[1])\n",
        "                outputs3_list.extend(outputs[2])\n",
        "                outputs4_list.extend(outputs[3])\n",
        "                # label_list.extend(labels.to('cpu').detach().clone().numpy())\n",
        "                df_error = pd.DataFrame({'prob0':outputs1_list,\n",
        "                                'prob1':outputs2_list,\n",
        "                                'prob2':outputs3_list,\n",
        "                                'prob3':outputs4_list,\n",
        "                                'id':id_list,\n",
        "                                'pred':preds_list})\n",
        "        df_errors = pd.merge(df_error, df_test, on='id')\n",
        "        body_len = []\n",
        "        # print('a')\n",
        "        for i in df_errors['description']:\n",
        "            body_len.append(len(i))\n",
        "        df_errors['len'] = body_len\n",
        "        train_x = df_errors[['id','prob0','prob1','prob2','prob3','pred','description']]\n",
        "        return train_x\n",
        "    \n",
        "    else:\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        bert_model.eval()\n",
        "        bert_model.to(device)\n",
        "        for batch in tqdm(load_dict[phase]): \n",
        "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "            inputs = batch[0].to(device)\n",
        "            id_list.extend(batch[2].to('cpu').detach().clone().numpy())\n",
        "            labels = batch[1].to(device) \n",
        "            \n",
        "            with torch.set_grad_enabled(False):\n",
        "                outputs_ = net_trained(inputs)\n",
        "                # loslogits = outputs\n",
        "                _, preds = torch.max(outputs_, 1)  # ラベルを予測\n",
        "                preds_list.extend(preds.to('cpu').detach().clone().numpy())\n",
        "                outputs = torch.t(outputs_).to('cpu').detach().clone().numpy()\n",
        "                outputs1_list.extend(outputs[0])\n",
        "                outputs2_list.extend(outputs[1])\n",
        "                outputs3_list.extend(outputs[2])\n",
        "                outputs4_list.extend(outputs[3])\n",
        "                label_list.extend(labels.to('cpu').detach().clone().numpy())\n",
        "                \n",
        "        df_error = pd.DataFrame({'prob0':outputs1_list,\n",
        "                                'prob1':outputs2_list,\n",
        "                                'prob2':outputs3_list,\n",
        "                                'prob3':outputs4_list,\n",
        "                                'id':id_list,\n",
        "                                'label':label_list,\n",
        "                                'pred':preds_list})\n",
        "        df_errors = pd.merge(df_error, df_train, on='id')\n",
        "        body_len = []\n",
        "        # print('a')\n",
        "        for i in df_errors['description']:\n",
        "            body_len.append(len(i))\n",
        "        df_errors['len'] = body_len\n",
        "        train_x = df_errors[['id','prob0','prob1','prob2','prob3','pred']]\n",
        "        train_y = df_errors['label']\n",
        "        return train_x, train_y"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iWi_sCEVWqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cc62d918-f983-40d7-c2af-53a87e8b01fc"
      },
      "source": [
        "train_x, train_y = make_df('train')\n",
        "val_x, val_y = make_df('val')\n",
        "test_x = make_df('test')\n",
        "print(f1_score(val_y, val_x['pred'], average='macro'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 145/145 [00:19<00:00,  7.55it/s]\n",
            "100%|██████████| 37/37 [00:05<00:00,  7.33it/s]\n",
            "100%|██████████| 109/109 [00:15<00:00,  7.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.4956028492089726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqcSCbShla2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6e97e035-4a93-4881-e2ee-cecec933664d"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec_count = TfidfVectorizer()\n",
        "vec = pd.concat([df_train['description'],df_test['description']])\n",
        "x = vec_count.fit_transform(vec)\n",
        "tf_df = pd.DataFrame(x.toarray(), columns=vec_count.get_feature_names())\n",
        "train_tf =tf_df[:2905]\n",
        "train_tf['id'] =np.arange(len(df_train))\n",
        "test_tf = tf_df[2905:]\n",
        "test_tf['id'] =np.arange(2931,4674)"
      ],
      "execution_count": 722,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOtJgcDv8iiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = pd.merge(train_x,train_tf, on = 'id')\n",
        "val_X = pd.merge(val_x, train_tf, on = 'id')\n",
        "test_X = pd.merge(test_x, test_tf, on = 'id')"
      ],
      "execution_count": 723,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNQXtxcJYVzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_id = test_X['id']\n",
        "del test_X['id']\n",
        "del test_X['description_x']\n",
        "del train_X['id']\n",
        "del val_X['id']"
      ],
      "execution_count": 724,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA2oSS1qFnK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cv = KFold(n_splits=5, shuffle = True, random_state=1234)\n",
        "params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'metric': 'multi_error',\n",
        "    'objective': 'multiclass',\n",
        "    'seed': 20,\n",
        "    'learning_rate': 0.01,\n",
        "    \"n_jobs\": -1,\n",
        "    \"verbose\": -1,\n",
        "    'num_class': 4\n",
        "}"
      ],
      "execution_count": 728,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr0zSwhyHj9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "18e0de02-4e9a-4369-d579-cffca8b9e8f2"
      },
      "source": [
        "\n",
        "train_set = lgb.Dataset(train_X, train_y)\n",
        "val_set = lgb.Dataset(val_X,val_y)\n",
        "lgb_model = lgb.train(params, train_set,num_boost_round=30000, early_stopping_rounds=3000,\n",
        "                      valid_sets = [train_set, val_set], verbose_eval = 500, feval =metric_f1)\n",
        "\n",
        "y_pred = lgb_model.predict(val_X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print(f1_score(y_pred, val_y, average='macro'))"
      ],
      "execution_count": 730,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 3000 rounds.\n",
            "[500]\ttraining's multi_error: 0.0525862\ttraining's metric_f1: 0.947274\tvalid_1's multi_error: 0.380379\tvalid_1's metric_f1: 0.562443\n",
            "[1000]\ttraining's multi_error: 0.00215517\ttraining's metric_f1: 0.997846\tvalid_1's multi_error: 0.392427\tvalid_1's metric_f1: 0.552905\n",
            "[1500]\ttraining's multi_error: 0\ttraining's metric_f1: 1\tvalid_1's multi_error: 0.392427\tvalid_1's metric_f1: 0.555564\n",
            "[2000]\ttraining's multi_error: 0\ttraining's metric_f1: 1\tvalid_1's multi_error: 0.392427\tvalid_1's metric_f1: 0.552958\n",
            "[2500]\ttraining's multi_error: 0\ttraining's metric_f1: 1\tvalid_1's multi_error: 0.394148\tvalid_1's metric_f1: 0.547331\n",
            "[3000]\ttraining's multi_error: 0\ttraining's metric_f1: 1\tvalid_1's multi_error: 0.388985\tvalid_1's metric_f1: 0.552012\n",
            "Early stopping, best iteration is:\n",
            "[20]\ttraining's multi_error: 0.201724\ttraining's metric_f1: 0.79833\tvalid_1's multi_error: 0.378657\tvalid_1's metric_f1: 0.569667\n",
            "0.5696667986610018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FXWBEXARw0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4e5abfc-eea0-414d-bd61-da65e4eb80ff"
      },
      "source": [
        "y_pred = lgb_model.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "submit = pd.DataFrame({'id':test_id,'pred':y_pred +1})\n",
        "submit.to_csv('submit6.csv',index=False, header=False)\n",
        "c = collections.Counter(y_pred +1)\n",
        "print(c)"
      ],
      "execution_count": 467,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({3: 625, 4: 449, 1: 442, 2: 227})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys__tNiavusq",
        "colab_type": "text"
      },
      "source": [
        "## submit用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyXqliX7Rf-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f25a8f8f-9579-4074-ebe7-219a8f21860a"
      },
      "source": [
        "from tqdm import tqdm\n",
        "preds_list = []\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "bert_model.eval()\n",
        "bert_model.to(device)\n",
        "\n",
        "\n",
        "for batch in tqdm(load_dict['test']): \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = batch[0].to(device)  \n",
        "    \n",
        "    with torch.set_grad_enabled(False):\n",
        "        outputs = net_trained(inputs)\n",
        "        # loslogits = outputs\n",
        "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "        preds_list.append(preds)"
      ],
      "execution_count": 454,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 109/109 [00:14<00:00,  7.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPE5Kq4DRf-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import datetime\n",
        "\n",
        "\n",
        "def submit_csv(test_id, preds,device):\n",
        "    dt_now = datetime.datetime.now()\n",
        "    time = dt_now.strftime('%Y年%m月%d日 %H:%M:%S')\n",
        "    label_list = []\n",
        "    if device == 'cpu':\n",
        "        preds = list(map(lambda x: x+1, preds))\n",
        "        submit = pd.DataFrame({'id':test_id,'pred':preds})\n",
        "        submit.to_csv('submit.csv',index=False, header=False)\n",
        "        print('完了cpu')\n",
        "    else:\n",
        "        for  i in preds_list:\n",
        "            labels = i.to('cpu').detach().numpy().copy()\n",
        "            label_list.extend(labels)\n",
        "        label_list = list(map(lambda x: x+1, label_list))\n",
        "        submit = pd.DataFrame({'id':test_id,'pred':label_list})\n",
        "        submit.to_csv('1_{}.csv'.format(time),index=False, header=False)\n",
        "        c = collections.Counter(label_list)\n",
        "        print(c)\n",
        "        print('完了GPU')\n"
      ],
      "execution_count": 457,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJpWozP2Rf-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fcb58a0-7695-4ce2-b8eb-8fa0a5a9b7d5"
      },
      "source": [
        "test_id = df_test['id'].to_list()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "label_list = submit_csv(test_id, preds,device)"
      ],
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({3: 694, 4: 499, 1: 459, 2: 91})\n",
            "完了GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfoVswaDlayp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "7265d323-7f3a-40e8-e2c4-7114b7518267"
      },
      "source": [
        "df_train"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>jobflag</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2904</th>\n",
              "      <td>Undertake to preprocess of structured and unst...</td>\n",
              "      <td>1</td>\n",
              "      <td>2904</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            description  jobflag    id\n",
              "2904  Undertake to preprocess of structured and unst...        1  2904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgOxCZ9Cl33I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5512894-c01e-4170-c135-a3f6ce7e7190"
      },
      "source": [
        "803 + 387 + 301 + 252"
      ],
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAfmAdVhmswm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeG1lPHD3Eq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBS_qCFQnOfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "71e02a4c-09c9-4e0e-f181-a5687e6f062c"
      },
      "source": [
        ""
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Executes and writes portions of testing plans, protocols, and documentation for assigned portion of application; identifies and debugs issues with code and suggests changes or improvements.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iAyJlmwnDVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}