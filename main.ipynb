{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfvxzzFBRj0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a079de3-3bf5-4615-f4e2-259fc2934709"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoUyjQ1RRrr2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "0cc69d17-990e-435b-fd6e-189ace1ce6d4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izuRkSW9Rf9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "# from transformers.modeling_bert import BertModel\n",
        "from transformers import BertTokenizer, BertForPreTraining, BertModel,BertForSequenceClassification\n",
        "from sklearn.metrics import precision_score\n",
        "import torch\n",
        "from torch import nn\n",
        "import json\n",
        "import torchtext\n",
        "import string\n",
        "import random\n",
        "import sys\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import lightgbm as lgb\n",
        "from matplotlib_venn import venn2\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.decomposition import NMF,LatentDirichletAllocation,TruncatedSVD"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT6p55ojRf9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/My Drive/data/train1.csv')\n",
        "df_test = pd.read_csv('/content/drive/My Drive/data/test1.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VliacrO0Rf9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9af92436-e21b-49d3-d722-4d6915d74f8f"
      },
      "source": [
        "df_train['jobflag'] = df_train['jobflag']-1\n",
        "df_train['jobflag'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1376\n",
              "0     624\n",
              "3     583\n",
              "1     348\n",
              "Name: jobflag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlGm0wVbyLeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yy = df_train['jobflag'].values\n",
        "weight = 1 / pd.DataFrame(yy).reset_index().groupby(0).count().values\n",
        "# weight = weight[train_y].ravel()\n",
        "# weight /= weight.sum()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhYjVnTbx7fx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "cbedd153-6f70-4d25-d7d6-f7c1656d557d"
      },
      "source": [
        "import numpy as np\n",
        "del df_train['id']\n",
        "df_train.drop_duplicates(subset='description', keep='last', inplace=True)\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_train['id'] = np.arange(2905)\n",
        "df_train"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>jobflag</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Executes and writes portions of testing plans,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Maintain Network Performance by assisting with...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Supports the regional compliance manager with ...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Keep up to date with local and national busine...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Assist with Service Organization Control (SOC)...</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2900</th>\n",
              "      <td>Preparation of reports for operational and man...</td>\n",
              "      <td>2</td>\n",
              "      <td>2900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2901</th>\n",
              "      <td>Line and/or indirect management of up to 20 st...</td>\n",
              "      <td>2</td>\n",
              "      <td>2901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2902</th>\n",
              "      <td>Partner with external agencies as needed</td>\n",
              "      <td>0</td>\n",
              "      <td>2902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2903</th>\n",
              "      <td>Design, Implement and test software for embedd...</td>\n",
              "      <td>2</td>\n",
              "      <td>2903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2904</th>\n",
              "      <td>Undertake to preprocess of structured and unst...</td>\n",
              "      <td>1</td>\n",
              "      <td>2904</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2905 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            description  jobflag    id\n",
              "0     Executes and writes portions of testing plans,...        1     0\n",
              "1     Maintain Network Performance by assisting with...        2     1\n",
              "2     Supports the regional compliance manager with ...        3     2\n",
              "3     Keep up to date with local and national busine...        0     3\n",
              "4     Assist with Service Organization Control (SOC)...        3     4\n",
              "...                                                 ...      ...   ...\n",
              "2900  Preparation of reports for operational and man...        2  2900\n",
              "2901  Line and/or indirect management of up to 20 st...        2  2901\n",
              "2902           Partner with external agencies as needed        0  2902\n",
              "2903  Design, Implement and test software for embedd...        2  2903\n",
              "2904  Undertake to preprocess of structured and unst...        1  2904\n",
              "\n",
              "[2905 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnGIp2SaRf94",
        "colab_type": "text"
      },
      "source": [
        "## tokenizer and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fteim849Rf94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_bert = BertTokenizer(vocab_file='/content/drive/My Drive/vocab/bert-base-uncased-vocab.txt')\n",
        "\n",
        "def preprocessing(text):\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "\n",
        "def token_same_len(token):\n",
        "    token.insert(0,'[CLS]')\n",
        "    if len(token) < 128:\n",
        "        while len(token) != 128:\n",
        "            token.insert(128,'[PAD]')\n",
        "    token.insert(127,'[SEP]')\n",
        "    return token\n",
        "\n",
        "def token_and_prepro(text, tokenizer = tokenizer_bert):\n",
        "    text = preprocessing(text)\n",
        "    token = tokenizer.tokenize(text)\n",
        "    token = token_same_len(token)\n",
        "    ids = tokenizer.convert_tokens_to_ids(token[:128])\n",
        "    return ids"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXfn6j5IRf96",
        "colab_type": "text"
      },
      "source": [
        "## dataset(torchtext)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VvTLJpORf97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer,token_same_len):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.token_same_len = token_same_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, input_ids):\n",
        "        text = self.df['description'][input_ids]\n",
        "        label = self.df['jobflag'][input_ids]\n",
        "        id = self.df['id'][input_ids]\n",
        "        \n",
        "        token = self.tokenizer(text)\n",
        "        \n",
        "        tensor_token = torch.tensor(token)\n",
        "        tensor_label = torch.tensor(label)\n",
        "        \n",
        "        return tensor_token, tensor_label, id"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aslS1UYLRf99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer,token_same_len):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.token_same_len = token_same_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, input_ids):\n",
        "        text = self.df['description'][input_ids]\n",
        "        id = self.df['id'][input_ids]\n",
        "        \n",
        "        token = self.tokenizer(text)\n",
        "        \n",
        "        tensor_token = torch.tensor(token)\n",
        "        \n",
        "        return tensor_token, id"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Lcg9kmBRf9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del df_test['id']\n",
        "dataset = Dataset(df = df_train, tokenizer = token_and_prepro,token_same_len=token_same_len)\n",
        "test_dataset = TestDataset(df = df_test, tokenizer = token_and_prepro,token_same_len=token_same_len)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.75)+1, int(len(dataset)*0.25)])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0XhpUerFxwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.sampler import BatchSampler\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "    \"\"\"\n",
        "    BatchSampler - from a MNIST-like dataset, samples n_classes and within these classes samples n_samples.\n",
        "    Returns batches of size n_classes * n_samples\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, n_classes, n_samples):\n",
        "        loader = DataLoader(dataset)\n",
        "        self.labels_list = []\n",
        "        for _, label,id in loader:\n",
        "            self.labels_list.append(label)\n",
        "        self.labels = torch.LongTensor(self.labels_list)\n",
        "        self.labels_set = list(set(self.labels.numpy()))\n",
        "        self.label_to_indices = {label: np.where(self.labels.numpy() == label)[0]\n",
        "                                 for label in self.labels_set}\n",
        "        for l in self.labels_set:\n",
        "            np.random.shuffle(self.label_to_indices[l])\n",
        "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
        "        self.count = 0\n",
        "        self.n_classes = n_classes\n",
        "        self.n_samples = n_samples\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = self.n_samples * self.n_classes\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.count = 0\n",
        "        while self.count + self.batch_size < len(self.dataset):\n",
        "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
        "            indices = []\n",
        "            for class_ in classes:\n",
        "                indices.extend(self.label_to_indices[class_][\n",
        "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
        "                                                                         class_] + self.n_samples])\n",
        "                self.used_label_indices_count[class_] += self.n_samples\n",
        "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
        "                    np.random.shuffle(self.label_to_indices[class_])\n",
        "                    self.used_label_indices_count[class_] = 0\n",
        "            yield indices\n",
        "            self.count += self.n_classes * self.n_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset) // self.batch_size"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in7OCMIXF38y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_sampler = BalancedBatchSampler(train_dataset, 4, 4)\n",
        "#train\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_sampler)\n",
        "# train_dataloader = torch.utils.data.DataLoader(train_dataset,  batch_size= 128, shuffle=True)\n",
        "#val\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size= 16, shuffle=False)\n",
        "#test\n",
        "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = False)\n",
        "#loader_dict\n",
        "load_dict = {\"train\":train_dataloader, 'val':val_dataloader,'test':dl_test}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aNRdRq3Rf-B",
        "colab_type": "text"
      },
      "source": [
        "## dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZq7Ke1Ui-Lw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6c8096e0-20e8-489c-a2b7-042eef63133a"
      },
      "source": [
        "print(tokenizer_bert.convert_ids_to_tokens(val_dataset.__getitem__(1)[0]))\n",
        "print(val_dataset.__getitem__(1)[2])\n",
        "print(df_train['description'][1757])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'design', ',', 'test', ',', 'and', 'modify', 'geo', '##sp', '##ati', '##al', 'big', '-', 'data', 'processing', 'algorithms', 'and', 'enable', 'implementation', 'in', 'either', 'python', 'or', 'java', 'suitable', 'for', 'a', 'cloud', '-', 'based', 'architecture', 'using', 'spark', ',', 'elastic', 'search', 'and', '/', 'or', 'had', '##oop', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[SEP]']\n",
            "521\n",
            "Review results with customer (within 2 days of job completion  if possible).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTDMTnvdRf-F",
        "colab_type": "text"
      },
      "source": [
        "## model構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQcNhaGARf-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertModel.from_pretrained(pretrained_model_name_or_path='bert-base-uncased')\n",
        "# model1 =BertForSequenceClassification.from_pretrained(pretrained_model_name_or_path='bert-base-uncased',num_labels=4)\n",
        "# print(model1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDi37mJmRf-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.bert = model\n",
        "        # self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(in_features=768, out_features=4)\n",
        "#         self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        nn.init.normal_(self.classifier.weight, std=0.02)\n",
        "        nn.init.normal_(self.classifier.bias, 0)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        output = self.bert(inputs)\n",
        "        vec_0 = output[0]  \n",
        "        vec_0 = vec_0[:, 0, :] \n",
        "        vec_0 = vec_0.view(-1, 768)\n",
        "        \n",
        "        result = self.classifier(vec_0)\n",
        "        \n",
        "        return result"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCBwODPvRf-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "615d6434-bd73-4bee-f5af-80d0abc7ea9f"
      },
      "source": [
        "bert_model = BERT()\n",
        "bert_model.train()\n",
        "print('a')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-nNWVJSRf-M",
        "colab_type": "text"
      },
      "source": [
        "### 勾配の計算場所"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD2YRe5URf-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.勾配計算Falseにする（ALl）\n",
        "for param in bert_model.parameters():\n",
        "    param.requires_grad = False\n",
        "# 2. BertLayer[12]そう目\n",
        "for param in bert_model.bert.encoder.layer[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "# 3. label\n",
        "for param in bert_model.classifier.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0JWPWF3Rf-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8fbed044-c481-4b46-e158-14483b539dbf"
      },
      "source": [
        "df_train['jobflag'].value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1364\n",
              "0     622\n",
              "3     579\n",
              "1     340\n",
              "Name: jobflag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mctMcCX8Rf-Q",
        "colab_type": "text"
      },
      "source": [
        "### oprimzer and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLSsNOuDqdT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def metric_f1(preds, data):\n",
        "    \"\"\"\n",
        "    F1 evaluation function for lgbm model.\n",
        "    \"\"\"\n",
        "    y_true = data.get_label()\n",
        "    preds = preds.reshape(4, len(preds) // 4)\n",
        "    y_pred = np.argmax(preds, axis=0)\n",
        "    score = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    return \"metric_f1\", score, True"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwxcECJIRf-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    net.to(device)\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    # batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "    batch_size = 16\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()\n",
        "            else:\n",
        "                net.eval()\n",
        "\n",
        "            epoch_loss = 0.0\n",
        "            f1_batch =0\n",
        "            epoch_corrects = 0\n",
        "            iteration = 1\n",
        "            c = 0\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書型変数\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = batch[0].to(device)  # 文章\n",
        "                labels = batch[1].to(device)  # ラベル\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # BERTに入力\n",
        "                    outputs = net(inputs)\n",
        "                    \n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if (iteration %  50 == 0):  # 10iterに1度、lossを表示\n",
        "                            acc = (torch.sum(preds == labels.data)\n",
        "                                   ).double()/batch_size\n",
        "                            f1 = precision_score(preds.cpu().numpy(),\n",
        "                                                 labels.data.cpu().numpy(),\n",
        "                                                 average='macro')\n",
        "                            print(' All / batch　{} || Loss: {:.4f} | ACC：{}　| F1 :{}'.format(\n",
        "                                iteration, loss.item(),  acc, f1))\n",
        "                    \n",
        "                    \n",
        "\n",
        "                    iteration += 1\n",
        "\n",
        "                    # 損失と正解数の合計を更新\n",
        "                    epoch_loss += loss.item() * batch_size\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "                    f1_batch += f1_score(preds.to('cpu').detach().clone().numpy(), \n",
        "                                   labels.data.to('cpu').detach().clone().numpy(), \n",
        "                                   average='macro')\n",
        "                    # print(f1_batch)\n",
        "                    # if c ==26:\n",
        "                    #     sys.exit()\n",
        "                    # c +=1\n",
        "                    # print(c)\n",
        "                    # f1_batch += precision_score(preds.cpu().numpy(),\n",
        "                    #                         labels.data.cpu().numpy(),\n",
        "                    #                         average='macro')\n",
        "                    # print(f1_batch)\n",
        "                        \n",
        "            # epochごとのlossと正解率\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "            # f1s = f1_batch/ len(dataloaders_dict[phase].dataset)\n",
        "            # epoch_f1 = f1_batch/len(dataloaders_dict[phase].dataset)\n",
        "            ##########lineに送信##########################\n",
        "            if phase != 'train':\n",
        "                url = \"https://notify-api.line.me/api/notify\"\n",
        "                token = 'tQSMjodBp3mHEA6wGscIofzVyDUquKliy6diNv5eP78'\n",
        "                headers = {\"Authorization\" : \"Bearer \"+ token}\n",
        "                message =  'Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                            phase, epoch_loss, epoch_acc)\n",
        "                payload = {\"message\" :  message}\n",
        "                r = requests.post(url ,headers = headers ,params=payload)\n",
        "            ###############################################\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}  F1{}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc,1))\n",
        "\n",
        "    return net"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvh0wErkRf-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# BERTの元の部分はファインチューニング\n",
        "optimizer = optim.Adam([\n",
        "    {'params': bert_model.bert.encoder.layer[-1].parameters(), 'lr': 4e-5},\n",
        "    {'params': bert_model.classifier.parameters(), 'lr': 5e-5}\n",
        "],weight_decay = 0.001)\n",
        "# 損失関数の設定\n",
        "# weights = torch.tensor(weight).cuda()\n",
        "# print(weights)\n",
        "# weights = torch.tensor([0.5466237942122186,1.0,0.4244868035190616,0.9308681672025724]).cuda()\n",
        "# criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# criterion = nn.MultiMarginLoss()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8y9XVVj0K1H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3686dcab-ca1d-4e19-a0c3-f84ddb9d8c73"
      },
      "source": [
        "df_train['jobflag'].value_counts()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1364\n",
              "0     622\n",
              "3     579\n",
              "1     340\n",
              "Name: jobflag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riLG9iCxRf-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "8b898175-0fa0-4aef-a6a4-4a1a83e9d436"
      },
      "source": [
        "import requests\n",
        "num_epochs = 7\n",
        "net_trained = train_model(bert_model, load_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)\n",
        "#save\n",
        "torch.save(net_trained.state_dict(), 'model.pth')\n",
        "#load\n",
        "# the_model = TheModelClass(*args, **kwargs)\n",
        "# the_model.load_state_dict(torch.load('model.pth'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " All / batch　50 || Loss: 1.4307 | ACC：0.125　| F1 :0.125\n",
            " All / batch　100 || Loss: 1.4269 | ACC：0.1875　| F1 :0.1875\n",
            "Epoch 1/7 | train |  Loss: 1.3536 Acc: 0.3098  F11\n",
            "Epoch 1/7 |  val  |  Loss: 1.1855 Acc: 0.4669  F11\n",
            " All / batch　50 || Loss: 1.3561 | ACC：0.375　| F1 :0.375\n",
            " All / batch　100 || Loss: 1.2408 | ACC：0.5　| F1 :0.5\n",
            "Epoch 2/7 | train |  Loss: 1.0943 Acc: 0.5268  F11\n",
            "Epoch 2/7 |  val  |  Loss: 0.9764 Acc: 0.6088  F11\n",
            " All / batch　50 || Loss: 1.0579 | ACC：0.625　| F1 :0.625\n",
            " All / batch　100 || Loss: 0.9415 | ACC：0.5625　| F1 :0.5625\n",
            "Epoch 3/7 | train |  Loss: 0.9873 Acc: 0.5870  F11\n",
            "Epoch 3/7 |  val  |  Loss: 1.0131 Acc: 0.5937  F11\n",
            " All / batch　50 || Loss: 0.8045 | ACC：0.875　| F1 :0.875\n",
            " All / batch　100 || Loss: 0.9685 | ACC：0.5625　| F1 :0.5625\n",
            "Epoch 4/7 | train |  Loss: 0.9645 Acc: 0.5994  F11\n",
            "Epoch 4/7 |  val  |  Loss: 1.0081 Acc: 0.5937  F11\n",
            " All / batch　50 || Loss: 0.8275 | ACC：0.625　| F1 :0.625\n",
            " All / batch　100 || Loss: 1.0669 | ACC：0.4375　| F1 :0.4375\n",
            "Epoch 5/7 | train |  Loss: 0.9177 Acc: 0.6191  F11\n",
            "Epoch 5/7 |  val  |  Loss: 0.9975 Acc: 0.5992  F11\n",
            " All / batch　50 || Loss: 0.9047 | ACC：0.625　| F1 :0.625\n",
            " All / batch　100 || Loss: 1.2918 | ACC：0.4375　| F1 :0.4375\n",
            "Epoch 6/7 | train |  Loss: 0.8716 Acc: 0.6581  F11\n",
            "Epoch 6/7 |  val  |  Loss: 1.0720 Acc: 0.5468  F11\n",
            " All / batch　50 || Loss: 0.5557 | ACC：0.75　| F1 :0.75\n",
            " All / batch　100 || Loss: 0.9309 | ACC：0.5625　| F1 :0.5625\n",
            "Epoch 7/7 | train |  Loss: 0.8240 Acc: 0.6677  F11\n",
            "Epoch 7/7 |  val  |  Loss: 0.9530 Acc: 0.6157  F11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmEoRb6Wvzx9",
        "colab_type": "text"
      },
      "source": [
        "## 誤差分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFpe5OXtv2x6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "def make_df(phase):\n",
        "    preds_list = []\n",
        "    label_list = []\n",
        "    outputs1_list = []\n",
        "    outputs2_list = []\n",
        "    outputs3_list = []\n",
        "    outputs4_list = []\n",
        "    id_list = []\n",
        "    df_error = pd.DataFrame()\n",
        "    df_errors = pd.DataFrame()\n",
        "\n",
        "\n",
        "    if phase == 'test':\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        bert_model.eval()\n",
        "        bert_model.to(device)\n",
        "        for batch in tqdm(load_dict[phase]): \n",
        "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "            inputs = batch[0].to(device)\n",
        "            id_list.extend(batch[1].to('cpu').detach().clone().numpy())\n",
        "            \n",
        "            with torch.set_grad_enabled(False):\n",
        "                outputs_ = net_trained(inputs)\n",
        "                # loslogits = outputs\n",
        "                _, preds = torch.max(outputs_, 1)  # ラベルを予測\n",
        "                preds_list.extend(preds.to('cpu').detach().clone().numpy())\n",
        "                outputs = torch.t(outputs_).to('cpu').detach().clone().numpy()\n",
        "                outputs1_list.extend(outputs[0])\n",
        "                outputs2_list.extend(outputs[1])\n",
        "                outputs3_list.extend(outputs[2])\n",
        "                outputs4_list.extend(outputs[3])\n",
        "                # label_list.extend(labels.to('cpu').detach().clone().numpy())\n",
        "                df_error = pd.DataFrame({'prob0':outputs1_list,\n",
        "                                'prob1':outputs2_list,\n",
        "                                'prob2':outputs3_list,\n",
        "                                'prob3':outputs4_list,\n",
        "                                'id':id_list,\n",
        "                                'pred':preds_list})\n",
        "        df_errors = pd.merge(df_error, df_test, on='id')\n",
        "        body_len = []\n",
        "        # print('a')\n",
        "        for i in df_errors['description']:\n",
        "            body_len.append(len(i))\n",
        "        df_errors['len'] = body_len\n",
        "        train_x = df_errors[['id','prob0','prob1','prob2','prob3','pred','description']]\n",
        "        return train_x\n",
        "    \n",
        "    else:\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        bert_model.eval()\n",
        "        bert_model.to(device)\n",
        "        for batch in tqdm(load_dict[phase]): \n",
        "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "            inputs = batch[0].to(device)\n",
        "            id_list.extend(batch[2].to('cpu').detach().clone().numpy())\n",
        "            labels = batch[1].to(device) \n",
        "            \n",
        "            with torch.set_grad_enabled(False):\n",
        "                outputs_ = net_trained(inputs)\n",
        "                # loslogits = outputs\n",
        "                _, preds = torch.max(outputs_, 1)  # ラベルを予測\n",
        "                preds_list.extend(preds.to('cpu').detach().clone().numpy())\n",
        "                outputs = torch.t(outputs_).to('cpu').detach().clone().numpy()\n",
        "                outputs1_list.extend(outputs[0])\n",
        "                outputs2_list.extend(outputs[1])\n",
        "                outputs3_list.extend(outputs[2])\n",
        "                outputs4_list.extend(outputs[3])\n",
        "                label_list.extend(labels.to('cpu').detach().clone().numpy())\n",
        "                \n",
        "        df_error = pd.DataFrame({'prob0':outputs1_list,\n",
        "                                'prob1':outputs2_list,\n",
        "                                'prob2':outputs3_list,\n",
        "                                'prob3':outputs4_list,\n",
        "                                'id':id_list,\n",
        "                                'label':label_list,\n",
        "                                'pred':preds_list})\n",
        "        df_errors = pd.merge(df_error, df_train, on='id')\n",
        "        body_len = []\n",
        "        # print('a')\n",
        "        for i in df_errors['description']:\n",
        "            body_len.append(len(i))\n",
        "        df_errors['len'] = body_len\n",
        "        train_x = df_errors[['id','prob0','prob1','prob2','prob3','pred']]\n",
        "        train_y = df_errors['label']\n",
        "        return train_x, train_y"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iWi_sCEVWqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d12d60c5-7da9-4154-dcb1-0e5d4843e022"
      },
      "source": [
        "val_x, val_y = make_df('val')\n",
        "train_x, train_y = make_df('train')\n",
        "test_x = make_df('test')\n",
        "print(f1_score(val_y, val_x['pred'], average='macro'))\n",
        "url = \"https://notify-api.line.me/api/notify\"\n",
        "token = 'tQSMjodBp3mHEA6wGscIofzVyDUquKliy6diNv5eP78'\n",
        "headers = {\"Authorization\" : \"Bearer \"+ token}\n",
        "message =  f1_score(val_y, val_x['pred'], average='macro')\n",
        "payload = {\"message\" :  message}\n",
        "r = requests.post(url ,headers = headers ,params=payload)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 46/46 [00:10<00:00,  4.35it/s]\n",
            "100%|██████████| 136/136 [00:31<00:00,  4.30it/s]\n",
            "100%|██████████| 109/109 [00:25<00:00,  4.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5552924676549411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys__tNiavusq",
        "colab_type": "text"
      },
      "source": [
        "## submit用(only bert)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPE5Kq4DRf-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import collections\n",
        "import datetime\n",
        "\n",
        "\n",
        "def submit_csv(test_id, preds,device):\n",
        "    dt_now = datetime.datetime.now()\n",
        "    time = dt_now.strftime('%Y年%m月%d日 %H:%M:%S')\n",
        "    label_list = []\n",
        "    if device == 'cpu':\n",
        "        preds = list(map(lambda x: x+1, preds))\n",
        "        submit = pd.DataFrame({'id':test_id,'pred':preds})\n",
        "        submit.to_csv('submit.csv',index=False, header=False)\n",
        "        print('完了cpu')\n",
        "    else:\n",
        "        for  i in preds_list:\n",
        "            labels = i.to('cpu').detach().numpy().copy()\n",
        "            label_list.extend(labels)\n",
        "        label_list = list(map(lambda x: x+1, label_list))\n",
        "        submit = pd.DataFrame({'id':test_id,'pred':label_list})\n",
        "        submit.to_csv('1_{}.csv'.format(time),index=False, header=False)\n",
        "        c = collections.Counter(label_list)\n",
        "        url = \"https://notify-api.line.me/api/notify\"\n",
        "        token = 'tQSMjodBp3mHEA6wGscIofzVyDUquKliy6diNv5eP78'\n",
        "        headers = {\"Authorization\" : \"Bearer \"+ token}\n",
        "        message =  'bert only',c\n",
        "        payload = {\"message\" :  message}\n",
        "        r = requests.post(url ,headers = headers ,params=payload)\n",
        "        print(c)\n",
        "        print('完了GPU')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyXqliX7Rf-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e17d7ed-c990-47f6-96e7-41ace071a532"
      },
      "source": [
        "from tqdm import tqdm\n",
        "preds_list = []\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "bert_model.eval()\n",
        "bert_model.to(device)\n",
        "\n",
        "\n",
        "for batch in tqdm(load_dict['test']): \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = batch[0].to(device)  \n",
        "    \n",
        "    with torch.set_grad_enabled(False):\n",
        "        outputs = net_trained(inputs)\n",
        "        # loslogits = outputs\n",
        "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "        preds_list.append(preds)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 109/109 [00:24<00:00,  4.53it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJpWozP2Rf-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "18e43396-aa18-42df-fafe-ebbbf0a7a4ad"
      },
      "source": [
        "test_id = df_test['id'].to_list()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "label_list = submit_csv(test_id, preds,device)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-c9e04f9b4dec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'submit_csv' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQmNZZY-CgZw",
        "colab_type": "text"
      },
      "source": [
        "## lgb(tf-idf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqcSCbShla2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "n_comp = 100\n",
        "vec_count = TfidfVectorizer()\n",
        "vec = pd.concat([df_train['description'],df_test['description']])\n",
        "x = vec_count.fit_transform(vec)\n",
        "tf_df = pd.DataFrame(x.toarray(), columns=vec_count.get_feature_names())\n",
        "text_svd = TruncatedSVD(n_components=n_comp, algorithm='arpack',random_state=1234)\n",
        "df_svd = pd.DataFrame(text_svd.fit_transform(tf_df))\n",
        "df_svd.columns = ['svd_'+str(j+1) for j in range(n_comp)]\n",
        "use_cols = []\n",
        "# for col in tf_df.columns:\n",
        "#     if tf_df.shape[0]*0.0025<tf_df[col].sum()<tf_df.shape[0]*0.5:\n",
        "#         use_cols.append(col)\n",
        "# tf_df = tf_df[use_cols]\n",
        "train_tf =df_svd[:2905]\n",
        "train_tf['id'] =np.arange(len(df_train))\n",
        "test_tf = df_svd[2905:]\n",
        "test_tf['id'] =np.arange(2931,4674)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOtJgcDv8iiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = pd.merge(train_x,train_tf, on = 'id')\n",
        "val_X = pd.merge(val_x, train_tf, on = 'id')\n",
        "test_X = pd.merge(test_x, test_tf, on = 'id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNQXtxcJYVzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_id = test_X['id']\n",
        "del test_X['id']\n",
        "del test_X['description']\n",
        "del train_X['id']\n",
        "del val_X['id']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA2oSS1qFnK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cv = KFold(n_splits=5, shuffle = True, random_state=1234)\n",
        "# params = {\n",
        "#     'boosting_type': 'gbdt',\n",
        "#     'metric': 'multi_error',\n",
        "#     'objective': 'multiclass',\n",
        "#     'seed': 20,\n",
        "#     'learning_rate': 0.001,\n",
        "#     \"n_jobs\": -1,\n",
        "#     \"verbose\": -1,\n",
        "#     'num_class': 4\n",
        "# }\n",
        "SEED  =1234\n",
        "params = {\n",
        "        'objective': 'multiclass',\n",
        "        'num_class': 4,\n",
        "        'metric': 'custom',\n",
        "        'learning_rate': 0.005,\n",
        "        'max_depth': -1,\n",
        "        'num_leaves': 31,\n",
        "        'max_bin': 31,\n",
        "        'min_data_in_leaf': 3,\n",
        "        'verbose': -1,\n",
        "        'seed': SEED,\n",
        "        'drop_seed': SEED,\n",
        "        'data_random_seed':SEED\n",
        "    }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk4sU1uxz_xM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_value = train_y.values \n",
        "weight = 1 / pd.DataFrame(y_value).reset_index().groupby(0).count().values\n",
        "weight = weight[y_value].ravel()\n",
        "weight /= weight.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr0zSwhyHj9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = lgb.Dataset(train_X, train_y,weight=weight)\n",
        "val_set = lgb.Dataset(val_X,val_y)\n",
        "lgb_model = lgb.train(params, train_set,num_boost_round=10000, early_stopping_rounds=2500,\n",
        "                      valid_sets = [train_set, val_set], verbose_eval = 500, feval =metric_f1)\n",
        "\n",
        "y_pred = lgb_model.predict(val_X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print(f1_score(y_pred, val_y, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FXWBEXARw0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import datetime\n",
        "\n",
        "dt_now = datetime.datetime.now()\n",
        "time = dt_now.strftime('%Y年%m月%d日 %H:%M:%S')\n",
        "y_pred = lgb_model.predict(test_X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "submit = pd.DataFrame({'id':test_id,'pred':y_pred +1})\n",
        "submit.to_csv('submit_lgb_{}.csv'.format(time),index=False, header=False)\n",
        "c = collections.Counter(y_pred +1)\n",
        "url = \"https://notify-api.line.me/api/notify\"\n",
        "token = 'tQSMjodBp3mHEA6wGscIofzVyDUquKliy6diNv5eP78'\n",
        "headers = {\"Authorization\" : \"Bearer \"+ token}\n",
        "message =  'lgb bert',c\n",
        "payload = {\"message\" :  message}\n",
        "r = requests.post(url ,headers = headers ,params=payload)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzaIeZm-TqXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgb.plot_importance(lgb_model, importance_type=\"gain\", max_num_features=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDGyQqwK1Etd",
        "colab_type": "text"
      },
      "source": [
        "# やること\n",
        "# count vector\n",
        "# suchadulear\n",
        "#{3:610 ~ 625,4:450 ~ 500, 1:aroud 430,2,aroud 200}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YE_pwnCDW8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}