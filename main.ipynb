{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfvxzzFBRj0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0969e84-1364-4d67-d73a-1a8c4c06dd8d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoUyjQ1RRrr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izuRkSW9Rf9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "# from transformers.modeling_bert import BertModel\n",
        "from transformers import BertTokenizer, BertForPreTraining, BertModel,BertForSequenceClassification\n",
        "from sklearn.metrics import precision_score\n",
        "import torch\n",
        "from torch import nn\n",
        "import json\n",
        "import torchtext\n",
        "import string\n",
        "import random\n",
        "import sys"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT6p55ojRf9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/My Drive/data/train1.csv')\n",
        "df_test = pd.read_csv('/content/drive/My Drive/data/test1.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VliacrO0Rf9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5dfbad00-ec3a-414c-a5fe-0cae7969cdde"
      },
      "source": [
        "df_train['jobflag'] = df_train['jobflag'] -1\n",
        "df_train['jobflag'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1376\n",
              "0     624\n",
              "3     583\n",
              "1     348\n",
              "Name: jobflag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNYVkWgyRf92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.drop_duplicates(subset='description', keep='last', inplace=True)\n",
        "df_train = df_train.reset_index(drop=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnGIp2SaRf94",
        "colab_type": "text"
      },
      "source": [
        "## tokenizer and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fteim849Rf94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_bert = BertTokenizer(vocab_file='/content/drive/My Drive/vocab/bert-base-uncased-vocab.txt')\n",
        "\n",
        "def preprocessing(text):\n",
        "    return text\n",
        "\n",
        "\n",
        "def token_same_len(token):\n",
        "    token.insert(0,'[CLS]')\n",
        "    if len(token) < 512:\n",
        "        while len(token) != 512:\n",
        "            token.insert(512,'[PAD]')\n",
        "    token.insert(128,['SEP'])\n",
        "    return token\n",
        "\n",
        "def token_and_prepro(text, tokenizer = tokenizer_bert):\n",
        "    text = preprocessing(text)\n",
        "    token = tokenizer.tokenize(text)\n",
        "    token = token_same_len(token)\n",
        "    ids = tokenizer.convert_tokens_to_ids(token[:128])\n",
        "    return ids"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXfn6j5IRf96",
        "colab_type": "text"
      },
      "source": [
        "## dataset(torchtext)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VvTLJpORf97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer,token_same_len):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.token_same_len = token_same_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, input_ids):\n",
        "        text = self.df['description'][input_ids]\n",
        "        label = self.df['jobflag'][input_ids]\n",
        "        \n",
        "        token = self.tokenizer(text)\n",
        "        \n",
        "        tensor_token = torch.tensor(token)\n",
        "        tensor_label = torch.tensor(label)\n",
        "        \n",
        "        return tensor_token, tensor_label"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aslS1UYLRf99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer,token_same_len):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.token_same_len = token_same_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, input_ids):\n",
        "        text = self.df['description'][input_ids]\n",
        "        \n",
        "        token = self.tokenizer(text)\n",
        "        \n",
        "        tensor_token = torch.tensor(token)\n",
        "        \n",
        "        return tensor_token"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Lcg9kmBRf9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# del df_test['id']\n",
        "dataset = Dataset(df = df_train, tokenizer = token_and_prepro,token_same_len=token_same_len)\n",
        "test_dataset = TestDataset(df = df_test, tokenizer = token_and_prepro,token_same_len=token_same_len)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), int(len(dataset)*0.2)])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0XhpUerFxwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.sampler import BatchSampler\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "    \"\"\"\n",
        "    BatchSampler - from a MNIST-like dataset, samples n_classes and within these classes samples n_samples.\n",
        "    Returns batches of size n_classes * n_samples\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, n_classes, n_samples):\n",
        "        loader = DataLoader(dataset)\n",
        "        self.labels_list = []\n",
        "        for _, label in loader:\n",
        "            self.labels_list.append(label)\n",
        "        self.labels = torch.LongTensor(self.labels_list)\n",
        "        self.labels_set = list(set(self.labels.numpy()))\n",
        "        self.label_to_indices = {label: np.where(self.labels.numpy() == label)[0]\n",
        "                                 for label in self.labels_set}\n",
        "        for l in self.labels_set:\n",
        "            np.random.shuffle(self.label_to_indices[l])\n",
        "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
        "        self.count = 0\n",
        "        self.n_classes = n_classes\n",
        "        self.n_samples = n_samples\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = self.n_samples * self.n_classes\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.count = 0\n",
        "        while self.count + self.batch_size < len(self.dataset):\n",
        "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
        "            indices = []\n",
        "            for class_ in classes:\n",
        "                indices.extend(self.label_to_indices[class_][\n",
        "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
        "                                                                         class_] + self.n_samples])\n",
        "                self.used_label_indices_count[class_] += self.n_samples\n",
        "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
        "                    np.random.shuffle(self.label_to_indices[class_])\n",
        "                    self.used_label_indices_count[class_] = 0\n",
        "            yield indices\n",
        "            self.count += self.n_classes * self.n_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset) // self.batch_size"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in7OCMIXF38y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sampler = BalancedBatchSampler(train_dataset, 4, 4)\n",
        "val_sampler = BalancedBatchSampler(val_dataset, 4, 4)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_sampler)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_sampler=val_sampler)\n",
        "load_dict = {\"train\":train_dataloader, 'val':val_dataloader}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aNRdRq3Rf-B",
        "colab_type": "text"
      },
      "source": [
        "## dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYsCX0Y-Rf-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size= 16, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size= 16, shuffle=False)\n",
        "load_dict = {\"train\":train_dataloader, 'val':val_dataloader}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdXt_FsfRf-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTDMTnvdRf-F",
        "colab_type": "text"
      },
      "source": [
        "## model構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQcNhaGARf-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertModel.from_pretrained(pretrained_model_name_or_path='bert-base-uncased')\n",
        "# model1 =BertForSequenceClassification.from_pretrained(pretrained_model_name_or_path='bert-base-uncased',num_labels=4)\n",
        "# print(model1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDi37mJmRf-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.bert = model\n",
        "        # self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(in_features=768, out_features=4)\n",
        "#         self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        nn.init.normal_(self.classifier.weight, std=0.02)\n",
        "        nn.init.normal_(self.classifier.bias, 0)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        output = self.bert(inputs)\n",
        "        vec_0 = output[0]  \n",
        "        vec_0 = vec_0[:, 0, :] \n",
        "        vec_0 = vec_0.view(-1, 768)\n",
        "        \n",
        "        result = self.classifier(vec_0)\n",
        "        \n",
        "        return result"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCBwODPvRf-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = BERT()\n",
        "bert_model.train()\n",
        "# print(bert_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-nNWVJSRf-M",
        "colab_type": "text"
      },
      "source": [
        "### 勾配の計算場所"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD2YRe5URf-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.勾配計算Falseにする（ALl）\n",
        "for param in bert_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. BertLayer[12]そう目\n",
        "for param in bert_model.bert.encoder.layer[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 3. label\n",
        "for param in bert_model.classifier.parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0JWPWF3Rf-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9ef83ebd-7af0-4fa3-8d08-645f86685258"
      },
      "source": [
        "df_train['jobflag'].value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1364\n",
              "0     622\n",
              "3     579\n",
              "1     340\n",
              "Name: jobflag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mctMcCX8Rf-Q",
        "colab_type": "text"
      },
      "source": [
        "### oprimzer and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvh0wErkRf-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# BERTの元の部分はファインチューニング\n",
        "optimizer = optim.Adam([\n",
        "    {'params': bert_model.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
        "    {'params': bert_model.classifier.parameters(), 'lr': 1e-4}\n",
        "])\n",
        "\n",
        "# 損失関数の設定\n",
        "# weights = torch.tensor([2.2,4.0,1.0,2.35]).cuda()\n",
        "# criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwxcECJIRf-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    net.to(device)\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # ミニバッチのサイズ\n",
        "    # batch_size = dataloaders_dict[\"train\"].batch_size\n",
        "    batch_size = 16\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()\n",
        "            else:\n",
        "                net.eval()\n",
        "\n",
        "            epoch_loss = 0.0\n",
        "            f1_batch =0\n",
        "            epoch_corrects = 0\n",
        "            iteration = 1\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書型変数\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = batch[0].to(device)  # 文章\n",
        "                labels = batch[1].to(device)  # ラベル\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # BERTに入力\n",
        "                    outputs = net(inputs)\n",
        "                    \n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        if (iteration % 25 == 0):  # 10iterに1度、lossを表示\n",
        "                            acc = (torch.sum(preds == labels.data)\n",
        "                                   ).double()/batch_size\n",
        "                            f1 = precision_score(preds.cpu().numpy(),\n",
        "                                                 labels.data.cpu().numpy(),\n",
        "                                                 average='macro')\n",
        "                            print(' All / batch　{} || Loss: {:.4f} | ACC：{}　| F1 :{}'.format(\n",
        "                                iteration, loss.item(),  acc, f1))\n",
        "                    \n",
        "                    \n",
        "\n",
        "                    iteration += 1\n",
        "\n",
        "                    # 損失と正解数の合計を更新\n",
        "                    epoch_loss += loss.item() * batch_size\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "                    # f1_batch += precision_score(preds.cpu().numpy(),\n",
        "                    #                         labels.data.cpu().numpy(),\n",
        "                    #                         average='macro')\n",
        "                    # print(f1_batch)\n",
        "                        \n",
        "            # epochごとのlossと正解率\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "            # epoch_f1 = f1_batch/len(dataloaders_dict[phase].dataset)\n",
        "            ##########lineに送信##########################\n",
        "            if phase != 'train':\n",
        "                url = \"https://notify-api.line.me/api/notify\"\n",
        "                token = 'tQSMjodBp3mHEA6wGscIofzVyDUquKliy6diNv5eP78'\n",
        "                headers = {\"Authorization\" : \"Bearer \"+ token}\n",
        "                message =  'Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                            phase, epoch_loss, epoch_acc)\n",
        "                payload = {\"message\" :  message}\n",
        "                r = requests.post(url ,headers = headers ,params=payload)\n",
        "            ###############################################\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return net"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riLG9iCxRf-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9ed42ab9-2212-4422-8dce-4afb7c022672"
      },
      "source": [
        "import requests\n",
        "num_epochs = 1\n",
        "net_trained = train_model(bert_model, load_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " All / batch　25 || Loss: 0.8428 | ACC：0.625　| F1 :0.625\n",
            " All / batch　50 || Loss: 0.6833 | ACC：0.625　| F1 :0.625\n",
            " All / batch　75 || Loss: 1.1528 | ACC：0.375　| F1 :0.375\n",
            " All / batch　100 || Loss: 0.7495 | ACC：0.625　| F1 :0.625\n",
            " All / batch　125 || Loss: 0.9930 | ACC：0.5　| F1 :0.5\n",
            "Epoch 1/1 | train |  Loss: 0.8628 Acc: 0.6377\n",
            "Epoch 1/1 |  val  |  Loss: 1.0991 Acc: 0.5284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyXqliX7Rf-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62d1333c-3876-4103-f857-79efed640449"
      },
      "source": [
        "from tqdm import tqdm\n",
        "preds_list = []\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "bert_model.eval()\n",
        "bert_model.to(device)\n",
        "\n",
        "\n",
        "for batch in tqdm(dl_test): \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = batch.to(device)  \n",
        "    \n",
        "    with torch.set_grad_enabled(False):\n",
        "        outputs = net_trained(inputs)\n",
        "        # loslogits = outputs\n",
        "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "        preds_list.append(preds)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 109/109 [00:15<00:00,  7.03it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPE5Kq4DRf-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "def submit_csv(test_id, preds,device):\n",
        "    label_list = []\n",
        "    if device == 'cpu':\n",
        "        preds = list(map(lambda x: x+1, preds))\n",
        "        submit = pd.DataFrame({'id':test_id,'pred':preds})\n",
        "        submit.to_csv('submit.csv',index=False, header=False)\n",
        "        print('完了cpu')\n",
        "    else:\n",
        "        for  i in preds_list:\n",
        "            labels = i.to('cpu').detach().numpy().copy()\n",
        "            label_list.extend(labels)\n",
        "        label_list = list(map(lambda x: x+1, label_list))\n",
        "        submit = pd.DataFrame({'id':test_id,'pred':label_list})\n",
        "        submit.to_csv('submit1.csv',index=False, header=False)\n",
        "        c = collections.Counter(label_list)\n",
        "        print(c)\n",
        "        print('完了GPU')\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJpWozP2Rf-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "81363b2d-6b49-4112-b52c-3c239cc522d6"
      },
      "source": [
        "test_id = df_test['id'].to_list()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "label_list = submit_csv(test_id, preds,device)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({3: 670, 4: 499, 1: 421, 2: 153})\n",
            "完了GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BElwZXzTRf-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ストップワード\n",
        "# scoreと文字の長さをlgb"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsurAadU6-4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4798c702-d203-4c4f-f03b-4e986c3dbb3e"
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({3: 670, 4: 499, 1: 421, 2: 153})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4blCJxZ_a6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}